{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should not modify code in this cell\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "# Get numsents POS-tagged sentences from the treebank corpus\n",
    "def get_pos_data(numsents):\n",
    "\n",
    "    # Extract required number of sentences\n",
    "    sentences = treebank.tagged_sents()[:numsents]\n",
    "\n",
    "    # Initialize\n",
    "    sequences = []\n",
    "    symbols = set()\n",
    "    tag_set = set()\n",
    "    \n",
    "    # Go over each extracted sentence ...\n",
    "    for sentence in sentences:\n",
    "        for i in range(len(sentence)):\n",
    "            word, tag = sentence[i]\n",
    "            word = word.lower()  # normalize case\n",
    "            symbols.add(word)    # add this word\n",
    "            tag_set.add(tag)\n",
    "            sentence[i] = (word, tag)  # store tagged token\n",
    "        sequences.append(sentence)\n",
    "\n",
    "    # Return sequences, the list of tags and all the words that we saw\n",
    "    return sequences, list(tag_set), list(symbols)\n",
    "\n",
    "# Train the transition and emission probabilities\n",
    "def train():\n",
    "    print('Training HMM...')\n",
    "\n",
    "    # Use the first 5000 sentences from treebank corpus\n",
    "    labelled_sequences, states, symbols = get_pos_data(5000)\n",
    "    \n",
    "    # Define the estimator to be used for probability computation\n",
    "    estimator = lambda fd, bins: nltk.LidstoneProbDist(fd, 0.1, bins)\n",
    "    \n",
    "    # count occurences of starting states, transitions out of each state\n",
    "    # and output symbols observed in each state\n",
    "    freq_starts = nltk.FreqDist()\n",
    "    freq_transitions = nltk.ConditionalFreqDist()\n",
    "    freq_emissions = nltk.ConditionalFreqDist()\n",
    "    for sequence in labelled_sequences:\n",
    "        lasts = None\n",
    "        for token in sequence:\n",
    "            state = token[1]\n",
    "            symbol = token[0]\n",
    "            if lasts == None:\n",
    "                freq_starts[state] += 1\n",
    "            else:\n",
    "                freq_transitions[lasts][state] += 1\n",
    "            freq_emissions[state][symbol] += 1\n",
    "            lasts = state\n",
    "\n",
    "            # update the state and symbol lists\n",
    "            if state not in states:\n",
    "                states.append(state)\n",
    "            if symbol not in symbols:\n",
    "                symbols.append(symbol)\n",
    "\n",
    "    # create probability distributions (with smoothing)\n",
    "    N = len(states)\n",
    "    starts = estimator(freq_starts, N)\n",
    "    transitions = nltk.ConditionalProbDist(freq_transitions, estimator, N)\n",
    "    emissions = nltk.ConditionalProbDist(freq_emissions, estimator, len(symbols))\n",
    "                               \n",
    "    # Return the transition and emissions probabilities along with \n",
    "    # the list of all the states and output symbols\n",
    "    return starts, transitions, emissions, states, symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HMM...\n"
     ]
    }
   ],
   "source": [
    "from numpy import zeros, array, float32, int16, argmax\n",
    "from math import log, exp\n",
    "\n",
    "# call the train function\n",
    "priors, transitions, emissions, states, symbols = train()\n",
    "# suggestion: inspect these five variables to get a sense of the data and data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#from the handout's pseudocode \n",
    "def decode(sen):\n",
    "    symbols = re.findall(r\"[\\w']+|[.,!?;]\", sen)\n",
    "    \n",
    "    #matrix\n",
    "    lenS = len(states)\n",
    "    lenT = len(symbols)\n",
    "    backtracker = {}\n",
    "    viterbi = zeros((lenS, lenT), float32)\n",
    "\n",
    "    #initialization \n",
    "    for i in range(lenS):\n",
    "        s = states[i]\n",
    "        viterbi[i,0] = priors.logprob(s)+emissions[s].logprob(symbols[0])\n",
    "        backtracker[s,0] = 0\n",
    "        \n",
    "    #recursive  \n",
    "    for t in range(1, lenT):\n",
    "        for i in range(lenS):\n",
    "            m = 0 \n",
    "            for j in range(lenS):\n",
    "                temp = viterbi[j,t-1]+transitions[states[j]].logprob(states[i])+emissions[states[i]].logprob(symbols[t])\n",
    "                #update max\n",
    "                if m==0 or temp > m[0]:\n",
    "                    m = (temp, states[j])\n",
    "            #termination step \n",
    "            viterbi[i,t] = m[0]\n",
    "            backtracker[states[i], t] = m[1]\n",
    "     \n",
    "    n = 0\n",
    "    for i in range(lenS):\n",
    "        #max in last cell\n",
    "        temp = viterbi[i,lenT-1]\n",
    "        if n==0 or temp > n[0]:\n",
    "            n = (temp, states[i])\n",
    "    \n",
    "    var = n[1]\n",
    "    \n",
    "    trace = [var]\n",
    "    #backtracking\n",
    "    for t in range(lenT-1, 0, -1):\n",
    "        prev = backtracker[var, t]\n",
    "        trace.append(prev)\n",
    "        var = prev\n",
    "        \n",
    "    trace.reverse()\n",
    "    return trace, symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagViterbi(fname):\n",
    "        content = []\n",
    "        tagged_content = []\n",
    "        count = 0\n",
    "        \n",
    "        #read in file with one tokenized sentence per line\n",
    "        with open(fname) as f:\n",
    "            content = f.readlines()\n",
    "\n",
    "        # process each sentence/line\n",
    "        for line in content:\n",
    "            \n",
    "            sta= \"\"\n",
    "            \n",
    "            # decode the line using viterbi decoding\n",
    "            #tokens = line.split()\n",
    "            best_sequence, sentences = decode(line)\n",
    "            \n",
    "            for s in range(len(best_sequence)):\n",
    "                sta += sentences[s] + '/' + best_sequence[s] + \" \"\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print (\"The best sequence is: \")\n",
    "            #print (best_sequence)\n",
    "            print (sta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i/PRP wonder/VBZ how/WRB many/JJ miles/NNS i/PRP 've/VBP fallen/VBN by/IN this/DT time/NN ./. \n",
      "i/PRP would/MD not/RB like/IN green/JJ eggs/NNS and/CC ham/NNS ./. \n",
      "emma/PRP spared/VBZ no/DT exertions/NN to/TO maintain/VB this/DT happier/JJ flow/NN of/IN ideas/NNS ./. \n",
      "while/IN these/DT things/NNS go/VBP up/RB other/JJ things/NNS come/VBP down/RB ./. \n",
      "if/IN it/PRP were/VBD a/DT hollywood/JJ movie/NN ,/, you/PRP 'd/MD never/RB believe/VBP it/PRP ./. \n"
     ]
    }
   ],
   "source": [
    "tagViterbi('test-sentences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the/DT report/NN is/VBZ subject/JJ to/TO review/VB ./. \n",
      "the/DT balance/NN is/VBZ n't/RB being/VBG budgeted/RP for/IN the/DT coming/VBG year/NN ./. \n",
      "we/PRP begin/VBP by/IN considering/VBG the/DT much/JJ simpler/JJ case/NN of/IN the/DT markov/JJ chain/NN ./. \n",
      "somewhere/NNP ,/, somebody/'' is/VBZ bound/-NONE- to/TO love/VB us/PRP ./. \n",
      "none/NN of/IN the/DT trujillo/JJ family/NN remains/VBZ ./. \n"
     ]
    }
   ],
   "source": [
    "tagViterbi('hw-sentences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
