{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You should not modify code in this cell\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "# Get numsents POS-tagged sentences from the treebank corpus\n",
    "def get_pos_data(numsents):\n",
    "\n",
    "    # Extract required number of sentences\n",
    "    sentences = treebank.tagged_sents()[:numsents]\n",
    "\n",
    "    # Initialize\n",
    "    sequences = []\n",
    "    symbols = set()\n",
    "    tag_set = set()\n",
    "    \n",
    "    # Go over each extracted sentence ...\n",
    "    for sentence in sentences:\n",
    "        for i in range(len(sentence)):\n",
    "            word, tag = sentence[i]\n",
    "            word = word.lower()  # normalize case\n",
    "            symbols.add(word)    # add this word\n",
    "            tag_set.add(tag)\n",
    "            sentence[i] = (word, tag)  # store tagged token\n",
    "        sequences.append(sentence)\n",
    "\n",
    "    # Return sequences, the list of tags and all the words that we saw\n",
    "    return sequences, list(tag_set), list(symbols)\n",
    "\n",
    "# Train the transition and emission probabilities\n",
    "def train():\n",
    "    print('Training HMM...')\n",
    "\n",
    "    # Use the first 5000 sentences from treebank corpus\n",
    "    labelled_sequences, states, symbols = get_pos_data(5000)\n",
    "    \n",
    "    # Define the estimator to be used for probability computation\n",
    "    estimator = lambda fd, bins: nltk.LidstoneProbDist(fd, 0.1, bins)\n",
    "    \n",
    "    # count occurences of starting states, transitions out of each state\n",
    "    # and output symbols observed in each state\n",
    "    freq_starts = nltk.FreqDist()\n",
    "    freq_transitions = nltk.ConditionalFreqDist()\n",
    "    freq_emissions = nltk.ConditionalFreqDist()\n",
    "    for sequence in labelled_sequences:\n",
    "        lasts = None\n",
    "        for token in sequence:\n",
    "            state = token[1]\n",
    "            symbol = token[0]\n",
    "            if lasts == None:\n",
    "                freq_starts[state] += 1\n",
    "            else:\n",
    "                freq_transitions[lasts][state] += 1\n",
    "            freq_emissions[state][symbol] += 1\n",
    "            lasts = state\n",
    "\n",
    "            # update the state and symbol lists\n",
    "            if state not in states:\n",
    "                states.append(state)\n",
    "            if symbol not in symbols:\n",
    "                symbols.append(symbol)\n",
    "\n",
    "    # create probability distributions (with smoothing)\n",
    "    N = len(states)\n",
    "    starts = estimator(freq_starts, N)\n",
    "    transitions = nltk.ConditionalProbDist(freq_transitions, estimator, N)\n",
    "    emissions = nltk.ConditionalProbDist(freq_emissions, estimator, len(symbols))\n",
    "                               \n",
    "    # Return the transition and emissions probabilities along with \n",
    "    # the list of all the states and output symbols\n",
    "    return starts, transitions, emissions, states, symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HMM...\n"
     ]
    }
   ],
   "source": [
    "from numpy import zeros, array, float32, int16, argmax\n",
    "from math import log, exp\n",
    "\n",
    "# call the train function\n",
    "priors, transitions, emissions, states, symbols = train()\n",
    "# suggestion: inspect these five variables to get a sense of the data and data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode(states, symbols):\n",
    "        # VITERBI DECODING\n",
    "        T = len(symbols) # sentence\n",
    "        N = len(states)\n",
    "        V = zeros((T, N), float32)\n",
    "        B = {}\n",
    "\n",
    "\n",
    "        for t in range(T):\n",
    "            symbol = symbols[t]\n",
    "            \n",
    "            #initialization step\n",
    "            if t == 0:\n",
    "                for i in xrange(N):\n",
    "                    state = self.states[i]\n",
    "                    V[t, i] = self.priors.prob(state) * \\\n",
    "                              self.emissions[state].prob(symbol)\n",
    "                    B[t, state] = None\n",
    "            else:\n",
    "                #recursion step\n",
    "                for j in xrange(N):\n",
    "                    sj = self.states[j]\n",
    "                    best = None\n",
    "                    for i in range(N):\n",
    "                        si = self.states[i]\n",
    "                        va = V[t-1, i] * self.transitions[si].prob(sj)\n",
    "                        if not best or va > best[0]:\n",
    "                            best = (va, si)\n",
    "                    #termination steps\n",
    "                    V[t, j] = best[0] * self.emissions[sj].prob(symbol)\n",
    "                    B[t, sj] = best[1]\n",
    "\n",
    "        best = None\n",
    "        for i in xrange(N):\n",
    "            val = V[T-1, i]\n",
    "            if not best or val > best[0]:\n",
    "                best = (val, self.states[i])\n",
    "\n",
    "\n",
    "        current = best[1]\n",
    "        sequence = [current]\n",
    "        for t in xrange(T-1, 0, -1):\n",
    "            last = B[t, current]\n",
    "            sequence.append(last)\n",
    "            current = last\n",
    "\n",
    "        sequence.reverse()\n",
    "        return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'states'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5fe63dab291c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'if it were a hollywood movie , you never believe it .'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2407baea1579>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, symbols)\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0;31m# VITERBI DECODING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'states'"
     ]
    }
   ],
   "source": [
    "list= decode(states, 'if it were a hollywood movie , you never believe it .')\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
